{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics of the de Volksbank Dataset\n",
    "\n",
    "This notebook provides the code to extract the statistics of the annotated and translated dataset. \n",
    "\n",
    "Additionally, the code at the end is used to split the data and checks the distribution. \n",
    "\n",
    "*Note: the output of some of the cells is hidden because the data is not allowed to be shared.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the needed packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# read in the complete annotated dataset\n",
    "#filepath can be changed to also get statistics about the merged datasets\n",
    "file_path = #filepath to the dataset\n",
    "new_df = pd.read_csv(file_path, delimiter=';', header= 0, dtype= str, keep_default_na=False, encoding= 'latin1', quotechar= '\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closer look at the first 5 rows of the data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some descriptive statistics: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closer look at the annotations of the topics and subtopics using 'groupby': "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overview distribution English topics\n",
    "new_df.groupby('CsatTopicEn').size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution in a Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.DataFrame()\n",
    "groups['total'] = new_df.groupby('CsatTopicEn').size()\n",
    "groups['dataversion'] = 'original'\n",
    "groups = groups.sort_values(by = ['total'])\n",
    "groups.plot(kind = 'barh', legend = False)\n",
    "plt.tight_layout()\n",
    "# uncomment if you wish to save the figure\n",
    "plt.savefig(r'\\figures\\distribution_topics_original.pdf', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview distribution English subtopics\n",
    "new_df.groupby('CsatSubtopicEn').size().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closer look at the feedback statements: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average length of the sentences\n",
    "\n",
    "lengths = []\n",
    "\n",
    "for sentence in new_df[\"Sentence_new_improved\"]:\n",
    "    lengths.append(len(word_tokenize(sentence)))\n",
    "    \n",
    "mean = sum(lengths)/len(lengths)\n",
    "print(\"Mean length of sentence: \") \n",
    "print(round(mean, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of tokens\n",
    "\n",
    "tokens = []\n",
    "for sentence in new_df['Sentence_new_improved'].astype(str):\n",
    "    [tokens.append(token) for token in word_tokenize(sentence)]\n",
    "\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the longest and the shortest feedback sequence\n",
    "\n",
    "def FindMaxLength(lst):\n",
    "    ''' \n",
    "    this function intends on finding the longest feedback sequence after the sequences have been tokenized\n",
    "    :param lst: the input is the list of tokens \n",
    "    :return: the tokens of the longest feedback sequence and the number of tokens\n",
    "    '''\n",
    "    maxList = max(lst, key = len)\n",
    "    maxLength = max(map(len, lst))\n",
    "      \n",
    "    return maxList, maxLength\n",
    "\n",
    "def FindMinLength(lst):\n",
    "    ''' \n",
    "    this function intends on finding the shortest feedback sequence after the sequences have been tokenized\n",
    "    :param lst: the input is the list of tokens \n",
    "    :return: the tokens of the shortest feedback sequence and the number of tokens\n",
    "    '''\n",
    "    minList = min(lst, key = len)\n",
    "    minLength = min(map(len, lst))\n",
    "      \n",
    "    return minList, minLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_statements=[]\n",
    "for sentence in new_df['Sentence_new_improved']: \n",
    "    feedback_statements.append(sentence)\n",
    "\n",
    "toks = []\n",
    "for s in feedback_statements:\n",
    "    tok = nltk.word_tokenize(s)\n",
    "    toks.append(tok)\n",
    "print('Max length token:', FindMaxLength(toks))\n",
    "\n",
    "for s in feedback_statements:\n",
    "    tok = nltk.word_tokenize(s)\n",
    "    toks.append(tok)\n",
    "print('Min length token:', FindMinLength(toks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a closer look at the n-grams\n",
    "n = 2\n",
    "ngram_frequencies = Counter()\n",
    "for sentence in new_df['Sentence_new_improved'].astype(str):\n",
    "    tokens_list = [tok.lower() for tok in word_tokenize(sentence)]\n",
    "    ngrams = [\" \".join(tokens_list[i:i+n]) for i in range(len(tokens_list)-n+1)]\n",
    "    ngram_frequencies.update(ngrams)\n",
    "\n",
    "\n",
    "print(ngram_frequencies.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#n-grams without the stopwords \n",
    "stops = set(stopwords.words('english'))\n",
    "# uncomment if you wish to see the stopwords\n",
    "#print(stops)\n",
    "\n",
    "\n",
    "frequent_ngrams = ngram_frequencies.most_common(200)\n",
    "for tokens, freq in frequent_ngrams: \n",
    "    \n",
    "    filter = False\n",
    "    \n",
    "    for token in tokens.split():\n",
    "        # remove punctuation\n",
    "        if token in string.punctuation: \n",
    "            filter = True\n",
    "        # remove stopwords\n",
    "        if token in stops: \n",
    "            filter = True\n",
    "    if not filter: \n",
    "        print(tokens, freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split\n",
    "The dataset is splitted in training, validation, and test sets. \n",
    "* 80% training\n",
    "* 10% validation\n",
    "* 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test_temp = train_test_split(new_df, test_size=0.20, random_state=5)\n",
    "test, validation = train_test_split(test_temp, test_size=0.50, random_state=0)\n",
    "\n",
    "#save the data\n",
    "\n",
    "train.to_csv(f\"/data/train.csv\",index=False, sep= ';')\n",
    "validation.to_csv(f\"/data/valid.csv\",index=False, sep= ';')\n",
    "test.to_csv(f\"/data/test.csv\",index=False, sep= ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We explore the stats of the training set to see the distribution of the training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r\"\\data\\train.csv\", delimiter=';', header= 0, dtype= str, keep_default_na=False, encoding= 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = train_df.groupby('CsatTopicEn').size() \n",
    "print(groups)\n",
    "groups.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(r\"\\data\\test.csv\", delimiter=';', header= 0, dtype= str, keep_default_na=False, encoding= 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = test_df.groupby('CsatTopicEn').size() \n",
    "print(groups)\n",
    "groups.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv(r\"\\data\\valid.csv\", delimiter=';', header= 0, dtype= str, keep_default_na=False, encoding= 'latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = valid_df.groupby('CsatTopicEn').size() \n",
    "print(groups)\n",
    "groups.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of the Notebook."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
